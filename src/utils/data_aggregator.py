from __future__ import annotations

import logging
from typing import Any, Dict, List, Optional

import pandas as pd

from src.services.intent_structurize_service import StructuredIntentResult

logger = logging.getLogger(__name__)


def merge_structured_intents_with_mysql(
    structured_intents: List[StructuredIntentResult],
    mysql_join_result: Dict[str, Any],
    min_count: int = 2
) -> pd.DataFrame:
    """
    å°†ç»“æ„åŒ–æ„å›¾æ•°æ®ä¸ MySQL æ•°æ®åˆå¹¶
    
    Args:
        structured_intents: ç»“æ„åŒ–æ„å›¾ç»“æœåˆ—è¡¨
        mysql_join_result: MySQL Join ç»“æœ
        min_count: æœ€å°é¢‘æ¬¡é˜ˆå€¼ï¼ˆç”¨äºè¿‡æ»¤ï¼‰
    
    Returns:
        pd.DataFrame: åˆå¹¶åçš„æ•°æ®æ¡†
    """
    # 1. æ„å»ºç»“æ„åŒ–æ„å›¾ DataFrame
    intent_data = []
    for result in structured_intents:
        if not result.success:
            continue
        
        material_id = result.materialId
        structured = result.structured_intent
        
        # æå–å…³é”®å­—æ®µ
        narrative = structured.get("narrative_analysis", {})
        tactical = structured.get("tactical_breakdown", {})
        
        intent_data.append({
            "materialId": material_id,
            "script_archetype": narrative.get("script_archetype", "Unknown"),
            "narrative_chain": narrative.get("narrative_chain", ""),
            "pacing": narrative.get("pacing", "Unknown"),
            "opening_strategy": tactical.get("opening_strategy", "Unknown"),
            "core_selling_points": tactical.get("core_selling_points", []),
            "closing_trigger": tactical.get("closing_trigger", "Unknown"),
            "dominant_emotion": tactical.get("dominant_emotion", "Unknown"),
        })
    
    if not intent_data:
        logger.warning("âš ï¸ [èšåˆ] æ²¡æœ‰æœ‰æ•ˆçš„ç»“æ„åŒ–æ„å›¾æ•°æ®")
        return pd.DataFrame()
    
    df_intents = pd.DataFrame(intent_data)
    logger.info(f"ğŸ“Š [èšåˆ] ç»“æ„åŒ–æ„å›¾æ•°æ®: {len(df_intents)} æ¡")
    
    # 2. æ„å»º MySQL æ•°æ® DataFrame
    mysql_data = mysql_join_result.get("mysql", {})
    mysql_rows = mysql_data.get("rows", [])
    
    if not mysql_rows:
        logger.warning("âš ï¸ [èšåˆ] æ²¡æœ‰ MySQL æ•°æ®")
        return pd.DataFrame()
    
    # ä» MySQL è¡Œæ•°æ®ä¸­æå–éœ€è¦çš„å­—æ®µ
    mysql_records = []
    for row in mysql_rows:
        mysql_records.append({
            "materialId": str(row.get("materialId", "")),
            "roi2": float(row.get("totalPrepayAndPayOrderRoi2", 0.0)) if row.get("totalPrepayAndPayOrderRoi2") else 0.0,
            "ctr": float(row.get("liveWatchCountForRoi2V2", 0)) / float(row.get("liveShowCountForRoi2V2", 1)) 
                   if row.get("liveShowCountForRoi2V2", 0) > 0 else 0.0,
            "cost": float(row.get("statCostForRoi2", 0.0)) if row.get("statCostForRoi2") else 0.0,
            "show_count": int(row.get("liveShowCountForRoi2V2", 0)) if row.get("liveShowCountForRoi2V2") else 0,
            "click_count": int(row.get("liveWatchCountForRoi2V2", 0)) if row.get("liveWatchCountForRoi2V2") else 0,
        })
    
    df_mysql = pd.DataFrame(mysql_records)
    logger.info(f"ğŸ“Š [èšåˆ] MySQL æ•°æ®: {len(df_mysql)} æ¡")
    
    # 3. åˆå¹¶æ•°æ®ï¼ˆåŸºäº materialIdï¼‰
    df_merged = pd.merge(df_intents, df_mysql, on="materialId", how="inner")
    
    if df_merged.empty:
        logger.warning("âš ï¸ [èšåˆ] åˆå¹¶åæ•°æ®ä¸ºç©ºï¼ˆmaterialId ä¸åŒ¹é…ï¼‰")
        return pd.DataFrame()
    
    logger.info(f"âœ… [èšåˆ] åˆå¹¶åæ•°æ®: {len(df_merged)} æ¡")
    return df_merged


def aggregate_by_dimension(
    df: pd.DataFrame,
    dimension: str,
    min_count: int = 2
) -> pd.DataFrame:
    """
    æŒ‰æŒ‡å®šç»´åº¦èšåˆæ•°æ®
    
    Args:
        df: åˆå¹¶åçš„æ•°æ®æ¡†
        dimension: èšåˆç»´åº¦ï¼ˆå¦‚ "opening_strategy", "script_archetype"ï¼‰
        min_count: æœ€å°é¢‘æ¬¡é˜ˆå€¼
    
    Returns:
        pd.DataFrame: èšåˆç»Ÿè®¡ç»“æœ
    """
    if df.empty or dimension not in df.columns:
        return pd.DataFrame()
    
    # èšåˆç»Ÿè®¡
    agg_stats = df.groupby(dimension).agg({
        "materialId": "count",  # é¢‘æ¬¡
        "roi2": "mean",  # å¹³å‡ ROI
        "ctr": "mean",  # å¹³å‡ CTR
        "cost": "sum",  # æ€»æ¶ˆè€—
        "show_count": "sum",  # æ€»æ›å…‰
        "click_count": "sum",  # æ€»ç‚¹å‡»
    }).reset_index()
    
    # é‡å‘½ååˆ—
    agg_stats.columns = ["tag", "count", "avg_roi", "avg_ctr", "total_cost", "total_show", "total_click"]
    
    # è¿‡æ»¤ä½é¢‘æ ‡ç­¾
    agg_stats = agg_stats[agg_stats["count"] >= min_count]
    
    # æŒ‰ count é™åºæ’åº
    agg_stats = agg_stats.sort_values("count", ascending=False)
    
    return agg_stats


def generate_aggregation_csv(
    structured_intents: List[StructuredIntentResult],
    mysql_join_result: Dict[str, Any],
    dimensions: Optional[List[str]] = None,
    min_count: int = 2
) -> str:
    """
    ç”Ÿæˆèšåˆç»Ÿè®¡çš„ CSV å­—ç¬¦ä¸²ï¼ˆç”¨äºå–‚ç»™ LLMï¼‰
    
    Args:
        structured_intents: ç»“æ„åŒ–æ„å›¾ç»“æœåˆ—è¡¨
        mysql_join_result: MySQL Join ç»“æœ
        dimensions: èšåˆç»´åº¦åˆ—è¡¨ï¼ˆé»˜è®¤ï¼šopening_strategy, script_archetype, closing_triggerï¼‰
        min_count: æœ€å°é¢‘æ¬¡é˜ˆå€¼
    
    Returns:
        str: CSV æ ¼å¼çš„ç»Ÿè®¡è¡¨
    """
    if dimensions is None:
        dimensions = ["opening_strategy", "script_archetype", "closing_trigger"]
    
    # åˆå¹¶æ•°æ®
    df_merged = merge_structured_intents_with_mysql(
        structured_intents,
        mysql_join_result,
        min_count
    )
    
    if df_merged.empty:
        logger.warning("âš ï¸ [èšåˆCSV] åˆå¹¶æ•°æ®ä¸ºç©ºï¼Œè¿”å›ç©º CSV")
        return "tag,count,avg_roi,avg_ctr\n"
    
    # å¯¹æ¯ä¸ªç»´åº¦è¿›è¡Œèšåˆ
    all_stats = []
    for dimension in dimensions:
        if dimension not in df_merged.columns:
            logger.warning(f"âš ï¸ [èšåˆCSV] ç»´åº¦ {dimension} ä¸å­˜åœ¨ï¼Œè·³è¿‡")
            continue
        
        stats = aggregate_by_dimension(df_merged, dimension, min_count)
        if not stats.empty:
            # æ·»åŠ ç»´åº¦æ ‡è¯†
            stats["dimension"] = dimension
            all_stats.append(stats)
    
    if not all_stats:
        logger.warning("âš ï¸ [èšåˆCSV] æ²¡æœ‰æœ‰æ•ˆçš„èšåˆç»Ÿè®¡")
        return "tag,count,avg_roi,avg_ctr\n"
    
    # åˆå¹¶æ‰€æœ‰ç»´åº¦çš„ç»Ÿè®¡
    df_all = pd.concat(all_stats, ignore_index=True)
    
    # é‡æ–°æ’åˆ—åˆ—é¡ºåº
    df_all = df_all[["dimension", "tag", "count", "avg_roi", "avg_ctr"]]
    
    # è½¬æ¢ä¸º CSV
    csv_str = df_all.to_csv(index=False)
    
    logger.info(f"âœ… [èšåˆCSV] ç”Ÿæˆ CSVï¼Œå…± {len(df_all)} è¡Œ")
    return csv_str

